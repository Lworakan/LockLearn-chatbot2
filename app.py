import os
import sys
import re
import gdown
import zipfile
import streamlit as st
import requests
import sqlite3

# --- Patch sqlite3 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Streamlit Cloud ---
__import__('pysqlite3')
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

from chromadb import PersistentClient
from sentence_transformers import SentenceTransformer

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤ Streamlit ---
st.set_page_config(page_title="LockLearn Lifecoach", page_icon="üíñ", layout="centered")

# --- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
folder_path = "./chromadb_database_v2/chromadb_database_v2"  # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
zip_file_path = "./chromadb_database_v2.zip"

# --- ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå zip vector database ‡∏à‡∏≤‡∏Å Google Drive ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
if not os.path.exists(folder_path):
    st.info("üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Vector DB) ‡∏à‡∏≤‡∏Å Google Drive...")

    # ‡∏•‡∏¥‡∏á‡∏Å‡πå Google Drive ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå zip ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤
    gdrive_file_id = "13MOEZbfRTuqM9g2ZJWllwynKbItB-7Ca"
    gdown.download(id=gdrive_file_id, output=zip_file_path, quiet=False, use_cookies=False)

    # ‡πÅ‡∏ï‡∏Å zip ‡πÑ‡∏ü‡∏•‡πå
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall("./chromadb_database_v2")  # ‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏°‡πà

    # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå zip ‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
    os.remove(zip_file_path)

    st.success("‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö tenant ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• chroma.sqlite3 ---
def get_existing_tenants(db_path):
    tenants = []
    if not os.path.exists(db_path):
        return tenants
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='tenants';")
        if cursor.fetchone():
            cursor.execute("SELECT id FROM tenants;")
            tenants = [row[0] for row in cursor.fetchall()]
        conn.close()
    except Exception as e:
        print(f"Error checking tenants: {e}")
    return tenants

# --- ‡πÇ‡∏´‡∏•‡∏î ChromaDB ‡πÅ‡∏ö‡∏ö persistent client ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ tenant ---
db_sqlite_path = os.path.join(folder_path, "chroma.sqlite3")

tenants = get_existing_tenants(db_sqlite_path)
st.write(f"‡∏û‡∏ö tenants ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {tenants}")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á tenant ‡πÄ‡∏≠‡∏á‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ tenant
if not tenants:
    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö tenant ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á tenant ‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏∑‡πà‡∏≠ 'default_tenant' ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏ô")
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á PersistentClient ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß (‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ tenant)
    try:
        client_tmp = PersistentClient(path=folder_path)
        client_tmp.create_tenant("default_tenant")
        tenants = ["default_tenant"]
        client_tmp.close()
    except Exception as e:
        st.error(f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á tenant ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        st.stop()

tenant_to_use = "default_tenant" if "default_tenant" in tenants else tenants[0]

try:
    client = PersistentClient(path=folder_path, tenant_id=tenant_to_use)
except Exception as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î ChromaDB ‡πÑ‡∏î‡πâ: {e}")
    st.stop()

# --- ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ collection "recommendations" ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á ---
try:
    collection = client.get_collection(name="recommendations")
except Exception:
    collection = client.create_collection(name="recommendations")

# --- ‡πÇ‡∏´‡∏•‡∏î embedding model ---
embedding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

# --- ‡πÇ‡∏´‡∏•‡∏î API Key ‡∏à‡∏≤‡∏Å secrets.toml ---
api_key = st.secrets["TOGETHER_API_KEY"]

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLaMA 4 Scout ‡∏ú‡πà‡∏≤‡∏ô Together AI ---
def query_llm_with_chat(prompt, api_key):
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 512,
    }
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return f"‚ùå API Error {response.status_code}: {response.text}"
    except Exception as e:
        return f"‚ùå Request failed: {e}"

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å ChromaDB ---
def retrieve_recommendations(question_embedding, top_k=10):
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=top_k
    )
    if results and results.get('documents'):
        return results['documents'][0]
    return []

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ---
def is_closing_message(text):
    closing_patterns = [
        r"^‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì.*", r"^‡∏Ç‡∏≠‡∏ö‡πÉ‡∏à.*", r"^‡πÇ‡∏≠‡πÄ‡∏Ñ.*", r"^‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à.*", r"^‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢.*", r"^‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏≤‡∏ö.*",
        r"^thank(s| you).*", r"^ok.*", r"^got it.*", r"^noted.*", r"^understood.*"
    ]
    text = text.strip().lower()
    if len(text.split()) <= 5:
        for pattern in closing_patterns:
            if re.match(pattern, text):
                return True
    return False

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à gibberish ‡∏´‡∏£‡∏∑‡∏≠ typo ‡∏á‡πà‡∏≤‡∏¢‡πÜ ---
def is_gibberish_or_typo(text):
    text = text.strip()
    if len(text) <= 2:
        return True
    words = text.split()
    if len(words) == 1 and not re.search(r'[a-zA-Z‡∏Å-‡πô]', words[0]):
        return True
    return False

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ ---
def detect_language(text):
    thai_chars = re.findall(r'[\u0E00-\u0E7F]', text)
    return "th" if len(thai_chars) / max(len(text), 1) > 0.3 else "en"

# --- Session state ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- UI ---
st.title("üíñ LockLearn Lifecoach")

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó
for entry in st.session_state.chat_history:
    with st.chat_message(entry["role"]):
        st.markdown(entry["content"])

user_input = st.chat_input("How can I support you today?")

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    lang = detect_language(user_input)

    if is_gibberish_or_typo(user_input):
        reply = {
            "th": "üòÖ ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏≠‡∏∞‡πÑ‡∏£ ‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö",
            "en": "üòÖ I'm not sure what you mean. Could you try rephrasing it?"
        }[lang]
    elif is_closing_message(user_input):
        reply = {
            "th": "üòä ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö!",
            "en": "üòä You're always welcome! Feel free to ask if you need more support!"
        }[lang]
    else:
        with st.spinner("Thinking..."):
            question_embedding = embedding_model.encode(user_input).tolist()
            recommendations = retrieve_recommendations(question_embedding, top_k=10)

            prompt = f"""
User message: "{user_input}"

Step 1: Briefly analyze the user's feelings or situation based on the message above.
Step 2: Using your analysis and the recommendations below, generate a supportive and practical response.

Recommendations:
"""
            for rec in recommendations:
                prompt += f"- {rec}\n"

            prompt += f"""

Please respond in {'Thai' if lang == 'th' else 'English'} with a {'polite and warm tone, ending sentences with "‡∏Ñ‡πà‡∏∞"' if lang == 'th' else 'kind and uplifting tone like a supportive female life coach'}.

Your response should:
- Reflect understanding of the user's feelings or situation.
- Naturally incorporate relevant recommendations.
- Avoid repeating the user's exact words or the recommendations verbatim.
- Be concise (1‚Äì2 sentences) and encouraging.
"""

            reply = query_llm_with_chat(prompt, api_key)

    st.session_state.chat_history.append({"role": "assistant", "content": reply})
    with st.chat_message("assistant", avatar="üßò‚Äç‚ôÄÔ∏è"):
        st.markdown(reply)
